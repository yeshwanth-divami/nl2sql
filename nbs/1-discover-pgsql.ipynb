{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c95a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp schemas.pgsql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42381408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AD_MAX_ITEMS=1000\n",
      "env: AD_SHOW_FULL_STRINGS=1\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%env AD_MAX_ITEMS=1000\n",
    "%env AD_SHOW_FULL_STRINGS=1\n",
    "from torch_snippets import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8863549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import datetime\n",
    "import re\n",
    "from torch_snippets import track2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c823796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class DbSchemaExplorer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        connection_string: str,\n",
    "        max_unique_values: int = 30,\n",
    "        required_tables=None,\n",
    "        blacklisted_tables=None,\n",
    "    ):\n",
    "        if required_tables is None:\n",
    "            required_tables = []\n",
    "        self.connection_string = connection_string\n",
    "        self.max_unique_values = max_unique_values\n",
    "        self.required_tables = required_tables\n",
    "        self.blacklisted_tables = blacklisted_tables or []\n",
    "\n",
    "        self.engine = create_engine(connection_string)\n",
    "        self.inspector = inspect(self.engine)\n",
    "\n",
    "        # Discover database name early (best-effort)\n",
    "        try:\n",
    "            self.database = self.engine.url.database or \"\"\n",
    "            if not self.database:\n",
    "                with self.engine.connect() as conn:\n",
    "                    self.database = (\n",
    "                        conn.execute(text(\"select current_database()\")).scalar() or \"\"\n",
    "                    )\n",
    "        except Exception:\n",
    "            self.database = \"\"\n",
    "\n",
    "        # Default schema (pgsql: public)\n",
    "        self.default_schema = (\n",
    "            getattr(self.inspector, \"default_schema_name\", None) or \"public\"\n",
    "        )\n",
    "\n",
    "        # Tables\n",
    "        self.table_names = self.inspector.get_table_names(schema=self.default_schema)\n",
    "        if self.required_tables:\n",
    "            if isinstance(self.required_tables, str):\n",
    "                self.table_names = [\n",
    "                    t for t in self.table_names if re.match(self.required_tables, t)\n",
    "                ]\n",
    "            elif isinstance(self.required_tables, list):\n",
    "                self.table_names = [\n",
    "                    t for t in self.table_names if t in self.required_tables\n",
    "                ]\n",
    "        if self.blacklisted_tables:\n",
    "            if isinstance(self.blacklisted_tables, str):\n",
    "                # regex filtering\n",
    "                self.table_names = [\n",
    "                    t\n",
    "                    for t in self.table_names\n",
    "                    if not re.match(self.blacklisted_tables, t)\n",
    "                ]\n",
    "            elif isinstance(self.blacklisted_tables, list):\n",
    "                self.table_names = [\n",
    "                    t for t in self.table_names if t not in self.blacklisted_tables\n",
    "                ]\n",
    "\n",
    "        # Primary keys map\n",
    "        self.pk_map = {}\n",
    "        for t in self.table_names:\n",
    "            try:\n",
    "                pk = (\n",
    "                    self.inspector.get_pk_constraint(t, schema=self.default_schema)\n",
    "                    or {}\n",
    "                )\n",
    "                self.pk_map[t] = set(pk.get(\"constrained_columns\", []) or [])\n",
    "            except Exception:\n",
    "                self.pk_map[t] = set()\n",
    "\n",
    "        # Foreign key references map\n",
    "        self.fk_ref_map = {t: {} for t in self.table_names}\n",
    "        for t in self.table_names:\n",
    "            try:\n",
    "                fks = (\n",
    "                    self.inspector.get_foreign_keys(t, schema=self.default_schema) or []\n",
    "                )\n",
    "                for fk in fks:\n",
    "                    cols = fk.get(\"constrained_columns\") or []\n",
    "                    ref_table = fk.get(\"referred_table\")\n",
    "                    ref_cols = fk.get(\"referred_columns\") or []\n",
    "                    for i, c in enumerate(cols):\n",
    "                        self.fk_ref_map[t][c] = {\n",
    "                            \"table\": ref_table,\n",
    "                            \"column\": ref_cols[i]\n",
    "                            if i < len(ref_cols)\n",
    "                            else (ref_cols[0] if ref_cols else None),\n",
    "                        }\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _iso_utc():\n",
    "        return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _quote_ident(s: str) -> str:\n",
    "        return '\"' + s.replace('\"', '\"\"') + '\"'\n",
    "\n",
    "    def describe_table(self, table: str) -> dict:\n",
    "        \"\"\"Return schema details for a single table.\"\"\"\n",
    "        with self.engine.begin() as conn:\n",
    "            return self._describe_table_with_conn(table, conn)\n",
    "\n",
    "    def _describe_table_with_conn(self, table: str, conn) -> dict:\n",
    "        # Row count\n",
    "        try:\n",
    "            row_count = int(\n",
    "                conn.execute(\n",
    "                    text(\n",
    "                        f\"SELECT COUNT(*) FROM {self._quote_ident(self.default_schema)}.{self._quote_ident(table)}\"\n",
    "                    )\n",
    "                ).scalar()\n",
    "                or 0\n",
    "            )\n",
    "        except SQLAlchemyError:\n",
    "            row_count = 0\n",
    "\n",
    "        # Columns\n",
    "        columns_info = []\n",
    "        try:\n",
    "            cols = self.inspector.get_columns(table, schema=self.default_schema) or []\n",
    "        except Exception:\n",
    "            cols = []\n",
    "\n",
    "        for col in cols:\n",
    "            col_name = col.get(\"name\")\n",
    "            data_type = str(col.get(\"type\"))\n",
    "            nullable = bool(col.get(\"nullable\", True))\n",
    "\n",
    "            default_val = col.get(\"default\", None)\n",
    "            if default_val is None:\n",
    "                default_val = col.get(\"server_default\", None)\n",
    "            if default_val is not None:\n",
    "                try:\n",
    "                    default_val = str(default_val)\n",
    "                except Exception:\n",
    "                    default_val = None\n",
    "\n",
    "            is_pk = col_name in self.pk_map.get(table, set())\n",
    "            fk_ref = self.fk_ref_map.get(table, {}).get(col_name)\n",
    "            is_fk = fk_ref is not None\n",
    "\n",
    "            distinct_count = 0\n",
    "            unique_values_field = None\n",
    "            try:\n",
    "                dq = text(\n",
    "                    f\"SELECT COUNT(DISTINCT {self._quote_ident(col_name)}) \"\n",
    "                    f\"FROM {self._quote_ident(self.default_schema)}.{self._quote_ident(table)}\"\n",
    "                )\n",
    "                dc = conn.execute(dq).scalar()\n",
    "                distinct_count = int(dc or 0)\n",
    "                if distinct_count <= self.max_unique_values:\n",
    "                    uvq = text(\n",
    "                        f\"SELECT DISTINCT {self._quote_ident(col_name)} \"\n",
    "                        f\"FROM {self._quote_ident(self.default_schema)}.{self._quote_ident(table)} \"\n",
    "                        f\"ORDER BY {self._quote_ident(col_name)} NULLS LAST \"\n",
    "                        f\"LIMIT {self.max_unique_values}\"\n",
    "                    )\n",
    "                    vals = [r[0] for r in conn.execute(uvq).fetchall()]\n",
    "                    safe_vals = []\n",
    "                    for v in vals:\n",
    "                        if isinstance(v, (str, int, float, bool)) or v is None:\n",
    "                            safe_vals.append(v)\n",
    "                        else:\n",
    "                            safe_vals.append(str(v))\n",
    "                    unique_values_field = safe_vals\n",
    "            except SQLAlchemyError:\n",
    "                distinct_count = 0\n",
    "                unique_values_field = None\n",
    "\n",
    "            col_entry = {\n",
    "                \"name\": col_name,\n",
    "                \"data_type\": data_type,\n",
    "                \"nullable\": nullable,\n",
    "                \"default\": default_val if default_val is not None else None,\n",
    "                \"is_primary_key\": is_pk,\n",
    "                \"is_foreign_key\": is_fk,\n",
    "                \"references\": fk_ref if is_fk else None,\n",
    "                \"distinct_count\": distinct_count,\n",
    "            }\n",
    "            if unique_values_field is not None:\n",
    "                col_entry[\"unique_values\"] = unique_values_field\n",
    "\n",
    "            columns_info.append(col_entry)\n",
    "\n",
    "        # Indexes\n",
    "        indexes = []\n",
    "        try:\n",
    "            idxs = self.inspector.get_indexes(table, schema=self.default_schema) or []\n",
    "            for idx in idxs:\n",
    "                indexes.append({\n",
    "                    \"name\": idx.get(\"name\"),\n",
    "                    \"columns\": idx.get(\"column_names\") or [],\n",
    "                    \"unique\": bool(idx.get(\"unique\", False)),\n",
    "                })\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return {\n",
    "            \"name\": table,\n",
    "            \"row_count\": row_count,\n",
    "            \"columns\": columns_info,\n",
    "            \"indexes\": indexes,\n",
    "        }\n",
    "\n",
    "    def to_json(self) -> dict:\n",
    "        result = {\n",
    "            \"database\": self.database,\n",
    "            \"generated_at\": self._iso_utc(),\n",
    "            \"tables\": [],\n",
    "        }\n",
    "        with self.engine.begin() as conn:\n",
    "            for table in track2(self.table_names):\n",
    "                result[\"tables\"].append(self._describe_table_with_conn(table, conn))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b45a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x_/48jwqq_s1_nbvttnq8z5d3k80000gp/T/ipykernel_16409/894401311.py:95: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 (112.06s  - 0.00s remaining - 1.70 iters/s)           \r"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/Users/yeshwanth/Code/Divami/foundry/nl2sql/.env/iirm.env\")\n",
    "\n",
    "user = os.environ[\"username\"]\n",
    "password = os.environ[\"password\"]\n",
    "dbhost = os.environ[\"hostname\"]\n",
    "dbname = os.environ[\"database\"]\n",
    "connection_string = f\"postgresql://{user}:{password}@{dbhost}/{dbname}\"\n",
    "\n",
    "explorer = DbSchemaExplorer(connection_string, blacklisted_tables=\"^zz_\")\n",
    "schemas = explorer.to_json()\n",
    "# You can now also access: explorer.engine, explorer.table_names, explorer.pk_map, explorer.fk_ref_map, explorer.default_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_schema: public\n",
      "tables: ['admin_reports_results_mappings', 'acl_category_action_map', 'acl_category_action_api_map', 'all_table_user_update_status', 'admin_reports', 'admin_reports_parameters', 'audit_history_log', 'document_processing_file', 'endorsement', 'acl_actions']\n"
     ]
    }
   ],
   "source": [
    "print(\"default_schema:\", explorer.default_schema)\n",
    "print(\"tables:\", explorer.table_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e924dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to = \"/Users/yeshwanth/Code/Divami/foundry/nl2sql/data/schemas/pgsql/iirm.txt\"\n",
    "makedir(parent(to))\n",
    "AD(schemas).write(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395260c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
